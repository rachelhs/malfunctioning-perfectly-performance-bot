import sys
import os
import time
from PIL import Image, ImageDraw, ImageFont, ImageColor
import cv2
import random
import numpy as np

# imports the Google Cloud client library
from google.cloud import language
from google.cloud.language import enums
from google.cloud.language import types
import speech_recognition as sr

from decouple import config
import openai

import json

#set initial variables
audience_speech = 'unknown'
fontsize = 20

#create fullscreen
cv2.namedWindow("Target", cv2.WND_PROP_FULLSCREEN)
cv2.setWindowProperty("Target",cv2.WND_PROP_FULLSCREEN,cv2.WINDOW_FULLSCREEN)

# imports text to speech library
from gtts import gTTS
# imports mp3 player library
import playsound

# get data from json file
with open("data.json") as jsonFile:
    data = json.load(jsonFile)
    jsonFile.close()

# generates a response with gtp-3 api
def gtp3_response(question):
    # load your API key from an environment variable or secret management service
    openai.api_key = config("OPENAI_API_KEY")
    # load prompts and settings from data stored in json file
    prompt = data[question]['api_prompt']
    temperature = data[question]['temperature']
    presence_penalty = data[question]['presence_penalty']
    frequency_penalty = data[question]['frequency_penalty']
    stop_sequences = data[question]['stop_sequences']

    # access Open AI GPT-3 API
    response_object = openai.Completion.create(engine="davinci", prompt=prompt, max_tokens=150, temperature=temperature, top_p=1, frequency_penalty=frequency_penalty, best_of=1, presence_penalty=presence_penalty, stop=stop_sequences)
    # single out the AI's response to the prompt
    response = response_object.choices[0].text

    # remove trailing half sentences
    # find the last instance of a punctuation mark in the text
    last_punctuation_mark = max(response.rfind(i) for i in "?.!")

    # if no punctuation is found at all, keep all of the text
    if (last_punctuation_mark == -1):
        response_full_sentences = response

    # otherwise keep the text up until the last punctuation mark
    else:
        response_full_sentences = response[0:(last_punctuation_mark+1)]
    
    return response_full_sentences

# selects an answer at random from the bank of answers
def random_response_from_bank(question):

    real_responses = data[question]['real_responses']
    response = real_responses[str((random.randrange(len(real_responses)))+1)]

    return response

# randomly select whether the response comes from a bank of answers or automatically generated ones
def choose_response(question):

    random_choice = random.randrange(2)
    if (random_choice == 0):
        print("answer from bank of questions")
        response = random_response_from_bank(question)
        return response
    else:
        print("answer generated by gpt-3")
        response = gtp3_response(question)
        return response

# selects a question at random to ask (for testing)
def ask_question():

    questions = list(data.keys())
    question = questions[random.randrange(len(questions))]
    print(data[question]['question'])
    return choose_response(str(question))

#for writing text to screen
def GenerateText(size, fontsize, bg, fg, text):
	#generate a piece of canvas and draw text on it
	canvas = Image.new('RGB', size, bg)
	draw = ImageDraw.Draw(canvas)
	grotesk = ImageFont.truetype("fonts/PxGrotesk-Screen.otf", fontsize)
	#first parameter is top left corner of text
	draw.text((0, 0), text, fg, font=grotesk)
	#change to BGR for opencv
	return cv2.cvtColor(np.array(canvas), cv2.COLOR_RGB2BGR)

def set_background():
	# sets white background image with target gender highlighted and static text
	global background
	background = cv2.imread('plain-background.jpeg')	

#display text on screen
def display_audience_speech():
	audience_speech_text = GenerateText((800, 20), 20, 'yellow', 'black', f"Heard: {audience_speech}")
	background[380: 400 ,0: 800] = audience_speech_text

def display_listening(toggle):
    print(toggle)
    if toggle:
        listening_text = GenerateText((800, 20), 20, 'yellow', 'black', "Listening...")
        background[20: 40 ,0: 800] = listening_text
        cv2.imshow('Target', background)
        
    else:
        processing_text = GenerateText((800, 20), 20, 'yellow', 'black', "Processing...")
        background[20: 40 ,0: 800] = processing_text
        cv2.imshow('Target', background)        

# listens for audience question
def recognise_question_from_speech():
    # obtain audio from the microphone
    r = sr.Recognizer()
    with sr.Microphone() as source:
        display_listening(True)
        print("Listening")
        #https://github.com/Uberi/speech_recognition/blob/master/reference/library-reference.rst
        #timeout is how long it will listen for if nothing is detected (None means no limit)
        timeout = None
        phrase_time_limit = 5
        audio = r.listen(source, timeout, phrase_time_limit)
        display_listening(False)
        #audio = r.listen(source)
        print("processing")


    # recognize speech using Google speech to text
    try:
        text = u""+str(r.recognize_google(audio))
        print('Heard: {}'.format(text))
    except sr.UnknownValueError:
        print("Google could not understand audio")
        text = 'unknown'
    except sr.RequestError as e:
        print("Google error; {0}".format(e))
        text = 'unknown'

    os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'google-service-account/tokyo-comfort-320610-e45e3b8edd50.json'

    if ("chronically" in text) | ("chronic" in text) | ("late" in text):
        result = 'chronically_late'
        print('chronically_late')
    elif ("study" in text):
        result = 'help_study'
        print('help_study')
    elif ("do you take ADHD medication" in text) | ("meth" in text):
        result = 'adhd_medication'
        print('adhd_medication')
    elif("feel like" in text) | ("first went on" in text):
        result = 'first_feel_like_medication'
        print('first_feel_like_medication')
    elif("what is it like" in text) | ("to have ADHD" in text):
        result = 'what_is_it_like'
        print('what_is_it_like')
    elif("goodbye" in text):
        result = 'end'
        print('end')
    else:
        result = 'unknown'
    
    return result, text

#draw background for display (mode, (w, h), colour)
canvas = Image.new('RGB', (600, 800), (255, 255, 255))

set_background()
display_audience_speech()
display_listening(True)

while(True):
    
    # if user says goodbye, quit programme
    time.sleep(1)
    result, audience_speech = recognise_question_from_speech()
    print(audience_speech)
    display_audience_speech()
    cv2.imshow('Target', background)
    print('how many times???')

    while audience_speech != 'end':
        # otherwise listen for questions and respond on loop
        response = choose_response(result)
        print(response)
        # read out response (text to speech)
        language = 'en'
        audio = gTTS(text=response, lang=language, slow=False)
        # save audio
        audio.save("response.mp3")
        # play audio
        playsound.playsound("/Users/rachel/Documents/Malfunctioning-Perfectly/malfunctioning-perfectly-live-bot/response.mp3", True)
        result, audience_speech = recognise_question_from_speech()
        display_audience_speech()
        cv2.imshow('Target', background)
		
    if cv2.waitKey(1) & 0xFF == ord('q'):
	    break

cv2.destroyAllWindows()



